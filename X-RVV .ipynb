{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "ouwYIVoaXGrM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5VVbZ4LTrhu",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow;\n",
        "!pip install keras;\n",
        "!pip install opencv-python;\n",
        "!pip install matplotlib;\n",
        "!pip install pandas;\n",
        "!pip install numpy;\n",
        "!pip install scikit-learn;\n",
        "!pip install seaborn;\n",
        "!pip install matplotlib;\n",
        "!pip install transformers;\n",
        "!pip install tf-keras-vis --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "GGl8U6n83ox5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models tensorflow_addons\n",
        "!pip install git+https://github.com/qubvel/segmentation_models"
      ],
      "metadata": {
        "id": "lfxJCGDO4tHt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TfMKCXBUNu0"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91JzWTX7UDeY",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Preparation and Sample Image Display"
      ],
      "metadata": {
        "id": "foUdl5f47YWb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfoGYtV60LEV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import shutil\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/data'\n",
        "dataset_path = '/content/dataset'\n",
        "\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    os.makedirs(dataset_path)\n",
        "\n",
        "subfolders = [f for f in os.listdir(data_folder) if os.path.isdir(os.path.join(data_folder, f))]\n",
        "for folder in subfolders:\n",
        "    source_folder = os.path.join(data_folder, folder)\n",
        "    destination_folder = os.path.join(dataset_path, folder)\n",
        "\n",
        "    if not os.path.exists(destination_folder):\n",
        "        shutil.copytree(source_folder, destination_folder)\n",
        "    else:\n",
        "        print(f\"Folder {folder} already exists in {dataset_path}. Skipping.\")\n",
        "    print(f\"Copied {folder} to {destination_folder}\")\n",
        "\n",
        "\n",
        "all_image_paths = []\n",
        "for root, _, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            all_image_paths.append(os.path.join(root, file))\n",
        "\n",
        "if all_image_paths:\n",
        "    random_image_path = random.choice(all_image_paths)\n",
        "    img = mpimg.imread(random_image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Random Image from {random_image_path}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No images found in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Dataset Image Count by Class"
      ],
      "metadata": {
        "id": "2XwacJ2g7ltL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZDiSim-5vLg"
      },
      "outputs": [],
      "source": [
        "category_counts = {}\n",
        "for category in os.listdir(dataset_path):\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        num_images = len([f for f in os.listdir(category_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        category_counts[category] = num_images\n",
        "\n",
        "# Print the results:\n",
        "for category, count in category_counts.items():\n",
        "    print(f\"Category '{category}': {count} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count of Total Images"
      ],
      "metadata": {
        "id": "VPiXJ0nF8coB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWbID00oXQKB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/dataset'\n",
        "total_images = 0\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "               total_images += 1\n",
        "\n",
        "print(f\"Total number of images in the dataset: {total_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Loading, Preprocessing, and Splitting Setup"
      ],
      "metadata": {
        "id": "E-vtc_C28UzW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3Kimb2B3FTv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/data'\n",
        "dataset_path = '/content/dataset'\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "image_paths = []\n",
        "labels = []\n",
        "for root, _, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_paths.append(os.path.join(root, file))\n",
        "            labels.append(os.path.basename(os.path.dirname(os.path.join(root, file))))\n",
        "\n",
        "\n",
        "\n",
        "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "    temp_paths, temp_labels, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "def load_and_resize(path):\n",
        "    img = mpimg.imread(path)\n",
        "\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    return img\n",
        "\n",
        "train_images = np.array([load_and_resize(path) for path in train_paths])\n",
        "val_images = np.array([load_and_resize(path) for path in val_paths])\n",
        "test_images = np.array([load_and_resize(path) for path in test_paths])\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_labels_categorical = to_categorical(train_labels_encoded)\n",
        "val_labels_categorical = to_categorical(val_labels_encoded)\n",
        "test_labels_categorical = to_categorical(test_labels_encoded)\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_data = train_datagen.flow(\n",
        "    train_images,\n",
        "    train_labels_categorical,\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "val_data = val_datagen.flow(\n",
        "    val_images,\n",
        "    val_labels_categorical,\n",
        "    batch_size=32,\n",
        "\n",
        ")\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_data = test_datagen.flow(\n",
        "    test_images,\n",
        "    test_labels_categorical,\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11e101bb"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "train_class_counts = Counter(train_labels)\n",
        "print(\"Number of images per class in Training Set:\")\n",
        "for label, count in train_class_counts.items():\n",
        "    print(f\"Category '{label}': {count} images\")\n",
        "\n",
        "val_class_counts = Counter(val_labels)\n",
        "print(\"\\nNumber of images per class in Validation Set:\")\n",
        "for label, count in val_class_counts.items():\n",
        "    print(f\"Category '{label}': {count} images\")\n",
        "\n",
        "test_class_counts = Counter(test_labels)\n",
        "print(\"\\nNumber of images per class in Testing Set:\")\n",
        "for label, count in test_class_counts.items():\n",
        "    print(f\"Category '{label}': {count} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet50"
      ],
      "metadata": {
        "id": "H3fSstegapCi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zoAKt1BX9Q2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data,\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "print(\"\\nEvaluating the model on the test set...\")\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8mJlSBEdsaY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels_encoded\n",
        "report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIjmRwHcd1BM"
      },
      "outputs": [],
      "source": [
        "model.save('my_trained_model.h5')\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLZsnG4N8MuX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.load_model('my_trained_model.h5')\n",
        "\n",
        "\n",
        "random_index = np.random.randint(0, len(test_paths))\n",
        "image_path = test_paths[random_index]\n",
        "true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = keras.applications.resnet50.preprocess_input(img_array)\n",
        "\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otDqiZ1GeE2o"
      },
      "source": [
        "# ResNet152"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4BV_57AeAv_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet152\n",
        "\n",
        "\n",
        "base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data,\n",
        "    callbacks=[lr_reduction] # Add callbacks here\n",
        ")\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels_encoded\n",
        "report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(report)\n",
        "\n",
        "model.save('resnet152_trained_model.h5')\n",
        "print(\"ResNet152 model saved successfully!\")\n",
        "\n",
        "\n",
        "model = keras.models.load_model('resnet152_trained_model.h5')\n",
        "\n",
        "\n",
        "random_index = np.random.randint(0, len(test_paths))\n",
        "image_path = test_paths[random_index]\n",
        "true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = keras.applications.resnet_v2.preprocess_input(img_array)\n",
        "\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XFkYGyBkWH3"
      },
      "source": [
        "# ResNet101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdXERoIr8qK8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet import ResNet101, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data,\n",
        ")\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(report)\n",
        "\n",
        "\n",
        "model.save('my_trained_model_resnet101.h5')\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3uVEsK9krhz"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(report)\n",
        "\n",
        "\n",
        "model.save('my_trained_model_resnet101.h5')\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1ujTSI9y66k"
      },
      "source": [
        "#EfficientNetV2B0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSdsyFK7oJKr"
      },
      "outputs": [],
      "source": [
        "!pip install -U efficientnet_v2\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "base_model = EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=7, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data,\n",
        "    callbacks=[early_stopping, lr_reduction]  # Include the callbacks\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nEvaluating the EfficientNetV2B0 model on the test set...\")\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(report)\n",
        "\n",
        "\n",
        "model.save('efficientnetv2b0_trained_model.h5')\n",
        "print(\"EfficientNetV2B0 model saved successfully!\")\n",
        "\n",
        "\n",
        "random_index = np.random.randint(0, len(test_paths))\n",
        "image_path = test_paths[random_index]\n",
        "true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = keras.applications.efficientnet_v2.preprocess_input(img_array)\n",
        "\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Az402U4lzpw"
      },
      "source": [
        "#EfficientNetV2S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ah6tBBqovYv"
      },
      "outputs": [],
      "source": [
        "!pip install -U efficientnet_v2\n",
        "from tensorflow.keras.applications import EfficientNetV2S\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "base_model = EfficientNetV2S(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "num_classes = 4\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nEvaluating the EfficientNetV2S model on the test set...\")\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(report)\n",
        "\n",
        "\n",
        "model.save('efficientnetv2s_trained_model.h5')\n",
        "print(\"EfficientNetV2S model saved successfully!\")\n",
        "\n",
        "random_index = np.random.randint(0, len(test_paths))\n",
        "image_path = test_paths[random_index]\n",
        "true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = keras.applications.efficientnet_v2.preprocess_input(img_array)\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8GDeBaKR097"
      },
      "source": [
        "#EfficientNetB7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM09DWIap_Di"
      },
      "outputs": [],
      "source": [
        "#!pip install -U efficientnet\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "base_model = EfficientNetB7(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data,\n",
        "    callbacks=[early_stopping, lr_reduction]\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nEvaluating the EfficientNetB7 model on the test set...\")\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(report)\n",
        "\n",
        "model.save('efficientnetb7_trained_model.h5')\n",
        "print(\"EfficientNetB7 model saved successfully!\")\n",
        "\n",
        "random_index = np.random.randint(0, len(test_paths))\n",
        "image_path = test_paths[random_index]\n",
        "true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = keras.applications.efficientnet.preprocess_input(img_array)\n",
        "\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrZunJABPKl5"
      },
      "source": [
        "# MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn4liKlYxEPz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "IMG_SIZE = 224\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG3Z6Z2ux294"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyLEat8kdIP0"
      },
      "source": [
        "#VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYn-YIJQ4ABn"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data,\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nEvaluating the VGG16 model on the test set...\")\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(report)\n",
        "\n",
        "\n",
        "model.save('vgg16_trained_model.h5')\n",
        "print(\"VGG16 model saved successfully!\")\n",
        "\n",
        "random_index = np.random.randint(0, len(test_paths))\n",
        "image_path = test_paths[random_index]\n",
        "true_label = test_labels[random_index]\n",
        "\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP1N9kM5dE_C"
      },
      "source": [
        "#VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3AGGfPAN2FS"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data,\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating the VGG16 model on the test set...\")\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "y_pred = model.predict(test_data)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_)\n",
        "print(report)\n",
        "\n",
        "model.save('vgg16_trained_model.h5')\n",
        "print(\"VGG16 model saved successfully!\")\n",
        "\n",
        "random_index = np.random.randint(0, len(test_paths))\n",
        "image_path = test_paths[random_index]\n",
        "true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzjcjQeCultY"
      },
      "source": [
        "# Vision Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbdZOVnaCRe8"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm\n",
        "\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms, datasets\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class_names = ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor', 'no_tumor']\n",
        "\n",
        "\n",
        "data_path = '/content/dataset'\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "full_dataset = datasets.ImageFolder(data_path, transform=transform)\n",
        "\n",
        "\n",
        "total_size = len(full_dataset)\n",
        "train_size = int(0.8 * total_size)\n",
        "val_size = int(0.10 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "\n",
        "model = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=len(class_names))\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "best_val_acc = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lrs5YaV3IcmW"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "train_correct = 0\n",
        "train_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "train_accuracy = 100 * train_correct / train_total\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "test_accuracy = 100 * np.sum(np.array(y_true) == np.array(y_pred)) / len(y_true)\n",
        "print(f\"Testing Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# X-RVV"
      ],
      "metadata": {
        "id": "sbLxgl3WoBNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.applications import ResNet50, VGG19\n",
        "from keras.layers import Input, Dense, Dropout, concatenate, GlobalAveragePooling2D, Resizing, Rescaling\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from transformers import TFViTModel\n",
        "import segmentation_models as sm\n",
        "\n",
        "\n",
        "vit_model = TFViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "\n",
        "input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='input_layer')\n",
        "\n",
        "\n",
        "resnet = ResNet50(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "resnet_out = GlobalAveragePooling2D()(resnet.output)\n",
        "\n",
        "\n",
        "vgg = VGG19(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "vgg_out = GlobalAveragePooling2D()(vgg.output)\n",
        "\n",
        "\n",
        "vit_input = Resizing(224, 224)(input_tensor)\n",
        "vit_input = Rescaling(1./255)(vit_input)\n",
        "\n",
        "class TransposeLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.transpose(inputs, perm=[0, 3, 1, 2])\n",
        "\n",
        "vit_input_transposed = TransposeLayer()(vit_input)\n",
        "\n",
        "class ViTBranch(tf.keras.layers.Layer):\n",
        "    def call(self, inputs, training=False):\n",
        "        outputs = vit_model({'pixel_values': inputs})\n",
        "        return outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "vit_out = ViTBranch()(vit_input_transposed)\n",
        "\n",
        "\n",
        "merged = concatenate([resnet_out, vgg_out, vit_out])\n",
        "x = Dense(1024, activation='relu')(merged)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "classification_output = Dense(NUM_CLASSES, activation='softmax', name='classification_output')(x)\n",
        "\n",
        "\n",
        "segmentation_output = sm.Unet(\n",
        "    backbone_name='resnet34',\n",
        "    encoder_weights='imagenet',\n",
        "    classes=1,\n",
        "    activation='sigmoid'\n",
        ")(input_tensor)\n",
        "segmentation_output._name = 'segmentation_output'\n",
        "\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=[classification_output, segmentation_output], name=\"functional_37\")\n",
        "\n",
        "\n",
        "classification_model = Model(inputs=model.input, outputs=model.get_layer('classification_output').output, name=\"functional_37\")\n",
        "\n",
        "\n",
        "classification_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "classification_model.summary()\n"
      ],
      "metadata": {
        "id": "91vp0y60kPNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = classification_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=50,\n",
        "    callbacks=[\n",
        "        keras.callbacks.ModelCheckpoint('best_hybrid_model.keras', save_best_only=True)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "9uyCeZpF5dxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "\n",
        "classification_model = load_model('best_hybrid_model.keras', custom_objects={'TransposeLayer': TransposeLayer, 'ViTBranch': ViTBranch})\n"
      ],
      "metadata": {
        "id": "XuouWywom3yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t2VUeW_oqtgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    preds = classification_model.predict(images)\n",
        "    y_true.extend(tf.argmax(labels, axis=1).numpy())\n",
        "    y_pred.extend(tf.argmax(preds, axis=1).numpy())\n",
        "\n",
        "y_true = tf.convert_to_tensor(y_true)\n",
        "y_pred = tf.convert_to_tensor(y_pred)\n"
      ],
      "metadata": {
        "id": "VpjIVO0SiwK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = classification_model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "g4zyiyTkpd_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class_names = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "VuROSYiprHJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "y_true_auc = []\n",
        "y_prob = []\n",
        "\n",
        "\n",
        "for images, labels in test_ds:\n",
        "\n",
        "    probs = classification_model.predict(images, verbose=0)\n",
        "    y_true_auc.extend(tf.argmax(labels, axis=1).numpy())\n",
        "    y_prob.extend(probs)\n",
        "\n",
        "y_true_auc = np.array(y_true_auc)\n",
        "y_prob = np.array(y_prob)\n",
        "\n",
        "\n",
        "auc_score_ovr = roc_auc_score(y_true_auc, y_prob, multi_class='ovr')\n",
        "\n",
        "\n",
        "auc_score_macro = roc_auc_score(y_true_auc, y_prob, multi_class='ovr', average='macro')\n",
        "\n",
        "\n",
        "auc_score_weighted = roc_auc_score(y_true_auc, y_prob, multi_class='ovr', average='weighted')\n",
        "\n",
        "\n",
        "print(f\"\\nAUC Score (One-vs-Rest): {auc_score_ovr:.4f}\")\n",
        "print(f\"AUC Score (Macro Average): {auc_score_macro:.4f}\")\n",
        "print(f\"AUC Score (Weighted Average): {auc_score_weighted:.4f}\")\n",
        "\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "\n",
        "    y_true_class = (y_true_auc == i).astype(int)\n",
        "\n",
        "    y_prob_class = y_prob[:, i]\n",
        "    auc_class = roc_auc_score(y_true_class, y_prob_class)\n",
        "    print(f\"AUC for class '{class_name}': {auc_class:.4f}\")\n"
      ],
      "metadata": {
        "id": "KLdztCaHp2l5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(\"Confusion Matrix - Test Set\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Pw_g3YOopPC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "n_classes = len(class_names)\n",
        "\n",
        "for i in range(n_classes):\n",
        "\n",
        "    y_true_bin = (y_true_auc == i).astype(int)\n",
        "\n",
        "\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_bin, y_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curves for each class\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--') # plot the diagonal line\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve - Per Class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Plot separate ROC curves for each class\n",
        "for i in range(n_classes):\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for Class: {class_names[i]}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "sPAa2QyMqFI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-keras-vis --quiet\n"
      ],
      "metadata": {
        "id": "XZllGhoxS2Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vGO9n_tSHqn"
      },
      "source": [
        "#Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRVBtJDzZY28"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import numpy as np\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "\n",
        "augmented_train_dir = '/content/augmented_data'\n",
        "os.makedirs(augmented_train_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "augmentations_per_image = 3\n",
        "\n",
        "print(f\"Augmenting {len(train_paths)} training images. Generating {augmentations_per_image} augmented images per original image.\")\n",
        "\n",
        "for i, img_path in enumerate(train_paths):\n",
        "    try:\n",
        "        img = load_img(img_path)\n",
        "        x = img_to_array(img)\n",
        "        x = x.reshape((1,) + x.shape)\n",
        "\n",
        "\n",
        "        category = os.path.basename(os.path.dirname(img_path))\n",
        "\n",
        "\n",
        "        category_folder = os.path.join(augmented_train_dir, category)\n",
        "        os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "        prefix = f\"{os.path.splitext(os.path.basename(img_path))[0]}_aug\"\n",
        "\n",
        "\n",
        "        gen_count = 0\n",
        "        for batch in datagen.flow(x, batch_size=1, save_to_dir=category_folder, save_prefix=prefix, save_format='jpeg'):\n",
        "            gen_count += 1\n",
        "            if gen_count >= augmentations_per_image:\n",
        "                break\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error augmenting image {img_path}: {e}\")\n",
        "\n",
        "print(\"Augmentation process complete.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmented Data Splitting"
      ],
      "metadata": {
        "id": "_aVqEstwBWAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    '/content/augmented_data',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',  # for softmax output\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    '/content/augmented_data',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "TPzx4tNPmvwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "train_class_counts = Counter(train_labels)\n",
        "print(\"Training set class distribution:\")\n",
        "for class_name, count in train_class_counts.items():\n",
        "    print(f\"{class_name}: {count} images\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
        "\n",
        "\n",
        "val_class_counts = Counter(val_labels)\n",
        "print(\"Validation set class distribution:\")\n",
        "for class_name, count in val_class_counts.items():\n",
        "    print(f\"{class_name}: {count} images\")\n"
      ],
      "metadata": {
        "id": "MFD86IvAnC_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcznP3JOHh5N"
      },
      "source": [
        "#RESNET50 + DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZrONNfCmkRs"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Unfreezing layers for fine-tuning...\")\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "num_layers_to_unfreeze = 50\n",
        "\n",
        "for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
        "    layer.trainable = False\n",
        "print(f\"Unfrozen {num_layers_to_unfreeze} layers in the base model for fine-tuning.\")\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model recompiled for fine-tuning with a lower learning rate.\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "epochs_finetune = 50\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau # Import callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "print(f\"\\nStarting fine-tuning for {epochs_finetune} epochs...\")\n",
        "history_finetune = model.fit(\n",
        "    augmented_train_data,\n",
        "    epochs=epochs_finetune,\n",
        "    validation_data=val_data,\n",
        "    #callbacks=[early_stopping, lr_reduction]\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nEvaluating the fine-tuned ResNet50 model on the test set...\")\n",
        "loss_finetune, accuracy_finetune = model.evaluate(test_data)\n",
        "print(f\"Fine-tuned Test Loss: {loss_finetune}\")\n",
        "print(f\"Fine-tuned Test Accuracy: {accuracy_finetune}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\nClassification Report for Fine-tuned ResNet50:\")\n",
        "\n",
        "\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "y_pred_finetune = model.predict(test_data)\n",
        "y_pred_classes_finetune = np.argmax(y_pred_finetune, axis=1)\n",
        "report_finetune = classification_report(y_true, y_pred_classes_finetune, target_names=label_encoder.classes_)\n",
        "print(report_finetune)\n",
        "\n",
        "\n",
        "model.save('resnet50_finetuned_model.h5')\n",
        "print(\"Fine-tuned ResNet50 model saved successfully!\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_finetune.history['accuracy'])\n",
        "plt.plot(history_finetune.history['val_accuracy'])\n",
        "plt.title('Fine-tuned Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_finetune.history['loss'])\n",
        "plt.plot(history_finetune.history['val_loss'])\n",
        "plt.title('Fine-tuned Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jns9UeP7HuGN"
      },
      "source": [
        "#ResNet152 + DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjCvf7a0d3uc"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "print(\"Freezing base ResNet152 layers...\")\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled for initial training (base layers frozen).\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "epochs_initial = 20\n",
        "print(f\"\\nStarting initial training for {epochs_initial} epochs (base layers frozen)...\")\n",
        "history_initial = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs_initial,\n",
        "    validation_data=val_ds,\n",
        "    #callbacks=[early_stopping, lr_reduction]\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nUnfreezing layers for fine-tuning...\")\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "num_layers_to_unfreeze = 100\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
        "    layer.trainable = False\n",
        "print(f\"Unfrozen {num_layers_to_unfreeze} layers in the base model for fine-tuning.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "optimizer_finetune = Adam(learning_rate=0.00001)\n",
        "model.compile(optimizer=optimizer_finetune, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model recompiled for fine-tuning with a very low learning rate.\")\n",
        "model.summary()\n",
        "\n",
        "epochs_finetune = 50\n",
        "print(f\"\\nStarting fine-tuning for {epochs_finetune} epochs...\")\n",
        "\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    augmented_train_data,\n",
        "    epochs=epochs_finetune,\n",
        "    validation_data=val_data,\n",
        "    #callbacks=[early_stopping, lr_reduction]\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nEvaluating the fine-tuned ResNet152 model on the test set...\")\n",
        "loss_finetune, accuracy_finetune = model.evaluate(test_data)\n",
        "print(f\"Fine-tuned Test Loss: {loss_finetune}\")\n",
        "print(f\"Fine-tuned Test Accuracy: {accuracy_finetune}\")\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report for Fine-tuned ResNet152:\")\n",
        "\n",
        "\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "y_pred_finetune = model.predict(test_data)\n",
        "y_pred_classes_finetune = np.argmax(y_pred_finetune, axis=1)\n",
        "\n",
        "report_finetune = classification_report(y_true, y_pred_classes_finetune, target_names=label_encoder.classes_)\n",
        "print(report_finetune)\n",
        "\n",
        "\n",
        "model.save('resnet152_finetuned_model.h5')\n",
        "print(\"Fine-tuned ResNet152 model saved successfully!\")\n",
        "\n",
        "\n",
        "if 'test_paths' in globals() and 'test_labels' in globals():\n",
        "    random_index = np.random.randint(0, len(test_paths))\n",
        "    image_path = test_paths[random_index]\n",
        "    true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\nSkipping random prediction as test_paths or test_labels are not available.\")\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_initial.history['accuracy'] + history_finetune.history['accuracy'])\n",
        "plt.plot(history_initial.history['val_accuracy'] + history_finetune.history['val_accuracy'])\n",
        "plt.title('Combined Model Accuracy (Initial + Fine-tuning)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_initial.history['loss'] + history_finetune.history['loss'])\n",
        "plt.plot(history_initial.history['val_loss'] + history_finetune.history['val_loss'])\n",
        "plt.title('Combined Model Loss (Initial + Fine-tuning)')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIs0IV3Bw4Fa"
      },
      "source": [
        "#ResNet101 + DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfoj_oAcvR9O"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "print(\"Freezing base ResNet101 layers...\")\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled for initial training (base layers frozen).\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "epochs_initial = 20\n",
        "print(f\"\\nStarting initial training for {epochs_initial} epochs (base layers frozen)...\")\n",
        "history_initial = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs_initial,\n",
        "    validation_data=val_ds,\n",
        "    #callbacks=[early_stopping, lr_reduction]\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nUnfreezing layers for fine-tuning...\")\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "num_layers_to_unfreeze = 100\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
        "    layer.trainable = False\n",
        "print(f\"Unfrozen {num_layers_to_unfreeze} layers in the base model for fine-tuning.\")\n",
        "\n",
        "\n",
        "\n",
        "optimizer_finetune = Adam(learning_rate=0.00001)\n",
        "model.compile(optimizer=optimizer_finetune, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model recompiled for fine-tuning with a very low learning rate.\")\n",
        "model.summary()\n",
        "\n",
        "epochs_finetune = 50\n",
        "print(f\"\\nStarting fine-tuning for {epochs_finetune} epochs...\")\n",
        "\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs_finetune,\n",
        "    validation_data=val_ds,\n",
        "    #callbacks=[early_stopping, lr_reduction]\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nEvaluating the fine-tuned ResNet101 model on the test set...\")\n",
        "loss_finetune, accuracy_finetune = model.evaluate(test_data)\n",
        "print(f\"Fine-tuned Test Loss: {loss_finetune}\")\n",
        "print(f\"Fine-tuned Test Accuracy: {accuracy_finetune}\")\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report for Fine-tuned ResNet101:\")\n",
        "\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "y_pred_finetune = model.predict(test_data)\n",
        "y_pred_classes_finetune = np.argmax(y_pred_finetune, axis=1)\n",
        "report_finetune = classification_report(y_true, y_pred_classes_finetune, target_names=label_encoder.classes_)\n",
        "print(report_finetune)\n",
        "\n",
        "\n",
        "model.save('resnet101_finetuned_model.h5')\n",
        "print(\"Fine-tuned ResNet101 model saved successfully!\")\n",
        "\n",
        "\n",
        "if 'test_paths' in globals() and 'test_labels' in globals():\n",
        "    random_index = np.random.randint(0, len(test_paths))\n",
        "    image_path = test_paths[random_index]\n",
        "    true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\nSkipping random prediction as test_paths or test_labels are not available.\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "combined_accuracy = history_initial.history['accuracy'] + history_finetune.history['accuracy']\n",
        "combined_val_accuracy = history_initial.history['val_accuracy'] + history_finetune.history['val_accuracy']\n",
        "plt.plot(combined_accuracy)\n",
        "plt.plot(combined_val_accuracy)\n",
        "plt.title('Combined Model Accuracy (Initial + Fine-tuning)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "combined_loss = history_initial.history['loss'] + history_finetune.history['loss']\n",
        "combined_val_loss = history_initial.history['val_loss'] + history_finetune.history['val_loss']\n",
        "plt.plot(combined_loss)\n",
        "plt.plot(combined_val_loss)\n",
        "plt.title('Combined Model Loss (Initial + Fine-tuning)')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjSpOITm3AzQ"
      },
      "source": [
        "#EfficientNetV2B0 + DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31mb0qn47R4S"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "base_model = EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "print(\"Freezing base EfficientNetV2B0 layers for initial training...\")\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "num_classes = train_labels_categorical.shape[1]\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled for initial training (base layers frozen).\")\n",
        "model.summary()\n",
        "\n",
        "epochs_initial = 20\n",
        "print(f\"\\nStarting initial training for {epochs_initial} epochs (base layers frozen)...\")\n",
        "\n",
        "train_data_to_use = train_ds if 'augmented_train_data' in globals() and augmented_train_data.samples > 0 else train_data\n",
        "\n",
        "history_initial = model.fit(\n",
        "    train_data_to_use,\n",
        "    epochs=epochs_initial,\n",
        "    validation_data=val_ds,\n",
        "    #callbacks=[early_stopping, lr_reduction]\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nUnfreezing layers for fine-tuning...\")\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "num_layers_to_unfreeze = 50\n",
        "\n",
        "for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
        "    layer.trainable = False\n",
        "print(f\"Unfrozen {num_layers_to_unfreeze} layers in the base model for fine-tuning.\")\n",
        "\n",
        "\n",
        "optimizer_finetune = Adam(learning_rate=0.00001)\n",
        "model.compile(optimizer=optimizer_finetune, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model recompiled for fine-tuning with a very low learning rate.\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "epochs_finetune = 50\n",
        "print(f\"\\nStarting fine-tuning for {epochs_finetune} epochs...\")\n",
        "\n",
        "\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_data_to_use,\n",
        "    epochs=epochs_finetune,\n",
        "    validation_data=val_ds,\n",
        "    #callbacks=[early_stopping, lr_reduction]\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating the fine-tuned EfficientNetV2B0 model on the test set...\")\n",
        "\n",
        "loss_finetune, accuracy_finetune = model.evaluate(test_data)\n",
        "print(f\"Fine-tuned Test Loss: {loss_finetune}\")\n",
        "print(f\"Fine-tuned Test Accuracy: {accuracy_finetune}\")\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report for Fine-tuned EfficientNetV2B0:\")\n",
        "\n",
        "y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "y_pred_finetune = model.predict(test_data)\n",
        "y_pred_classes_finetune = np.argmax(y_pred_finetune, axis=1)\n",
        "report_finetune = classification_report(y_true, y_pred_classes_finetune, target_names=label_encoder.classes_)\n",
        "print(report_finetune)\n",
        "\n",
        "\n",
        "model.save('efficientnetv2b0_finetuned_model.h5')\n",
        "print(\"Fine-tuned EfficientNetV2B0 model saved successfully!\")\n",
        "\n",
        "\n",
        "if 'test_paths' in globals() and 'test_labels' in globals():\n",
        "    random_index = np.random.randint(0, len(test_paths))\n",
        "    image_path = test_paths[random_index]\n",
        "    true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = keras.applications.efficientnet_v2.preprocess_input(img_array)\n",
        "\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\nSkipping random prediction as test_paths or test_labels are not available.\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "combined_accuracy = history_initial.history['accuracy'] + history_finetune.history['accuracy']\n",
        "combined_val_accuracy = history_initial.history['val_accuracy'] + history_finetune.history['val_accuracy']\n",
        "plt.plot(combined_accuracy)\n",
        "plt.plot(combined_val_accuracy)\n",
        "plt.title('Combined Model Accuracy (Initial + Fine-tuning)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "combined_loss = history_initial.history['loss'] + history_finetune.history['loss']\n",
        "combined_val_loss = history_initial.history['val_loss'] + history_finetune.history['val_loss']\n",
        "plt.plot(combined_loss)\n",
        "plt.plot(combined_val_loss)\n",
        "plt.title('Combined Model Loss (Initial + Fine-tuning)')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1BNOGtjnzJF"
      },
      "source": [
        "#EfficientNetV2S + DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_IIXfny6g2p"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications import EfficientNetV2S\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import os\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "print(f\"Loading EfficientNetV2S model with input shape ({IMG_SIZE}, {IMG_SIZE}, 3)...\")\n",
        "base_model = EfficientNetV2S(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "print(\"Freezing base EfficientNetV2S layers for initial training...\")\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "if 'train_labels_categorical' not in globals():\n",
        "    print(\"Error: 'train_labels_categorical' is not defined. Cannot determine number of classes.\")\n",
        "\n",
        "    num_classes = 4\n",
        "    print(f\"Assuming {num_classes} classes.\")\n",
        "else:\n",
        "    num_classes = train_labels_categorical.shape[1]\n",
        "    print(f\"Detected {num_classes} classes from train_labels_categorical.\")\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled for initial training (base layers frozen).\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=7, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "train_data_to_use = train_ds if 'augmented_train_data' in globals() and augmented_train_data.samples > 0 else train_data\n",
        "\n",
        "if 'train_data' not in globals() and ('augmented_train_data' not in globals() or augmented_train_data.samples == 0):\n",
        "     print(\"Error: Training data generator ('train_data' or 'augmented_train_data') not found or is empty.\")\n",
        "else:\n",
        "\n",
        "    epochs_initial = 20\n",
        "    print(f\"\\nStarting initial training for {epochs_initial} epochs (base layers frozen)...\")\n",
        "\n",
        "\n",
        "    if 'val_data' not in globals():\n",
        "         print(\"Error: Validation data generator ('val_data') not found.\")\n",
        "    else:\n",
        "        history_initial = model.fit(\n",
        "            train_data_to_use,\n",
        "            epochs=epochs_initial,\n",
        "            validation_data=val_ds,\n",
        "            #callbacks=[early_stopping, lr_reduction]\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"\\nUnfreezing layers for fine-tuning...\")\n",
        "\n",
        "\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = True\n",
        "\n",
        "\n",
        "        num_layers_to_unfreeze = 50\n",
        "\n",
        "\n",
        "        for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
        "            layer.trainable = False\n",
        "        print(f\"Unfrozen {num_layers_to_unfreeze} layers in the base model for fine-tuning.\")\n",
        "\n",
        "\n",
        "        optimizer_finetune = Adam(learning_rate=0.001)\n",
        "        model.compile(optimizer=optimizer_finetune, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        print(\"Model recompiled for fine-tuning with a very low learning rate.\")\n",
        "        model.summary()\n",
        "\n",
        "\n",
        "        epochs_finetune = 50\n",
        "        print(f\"\\nStarting fine-tuning for {epochs_finetune} epochs...\")\n",
        "\n",
        "\n",
        "        history_finetune = model.fit(\n",
        "            train_data_to_use,\n",
        "            epochs=epochs_finetune,\n",
        "            validation_data=val_ds,\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"\\nEvaluating the fine-tuned EfficientNetV2S model on the test set...\")\n",
        "\n",
        "        if 'test_data' not in globals():\n",
        "            print(\"Error: Test data generator ('test_data') not found.\")\n",
        "        else:\n",
        "            loss_finetune, accuracy_finetune = model.evaluate(test_data)\n",
        "            print(f\"Fine-tuned Test Loss: {loss_finetune}\")\n",
        "            print(f\"Fine-tuned Test Accuracy: {accuracy_finetune}\")\n",
        "\n",
        "\n",
        "            print(\"\\nClassification Report for Fine-tuned EfficientNetV2S:\")\n",
        "\n",
        "\n",
        "            if 'test_labels_encoded' in globals() and 'label_encoder' in globals():\n",
        "\n",
        "                y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "                y_pred_finetune = model.predict(test_data)\n",
        "                y_pred_classes_finetune = np.argmax(y_pred_finetune, axis=1)\n",
        "\n",
        "                report_finetune = classification_report(y_true, y_pred_classes_finetune, target_names=label_encoder.classes_)\n",
        "                print(report_finetune)\n",
        "            else:\n",
        "                 print(\"Error: 'test_labels_encoded' or 'label_encoder' not found. Cannot generate classification report.\")\n",
        "\n",
        "\n",
        "            model.save('efficientnetv2s_finetuned_model.h5')\n",
        "            print(\"Fine-tuned EfficientNetV2S model saved successfully!\")\n",
        "\n",
        "\n",
        "            if 'test_paths' in globals() and 'test_labels' in globals() and 'label_encoder' in globals():\n",
        "                random_index = np.random.randint(0, len(test_paths))\n",
        "                image_path = test_paths[random_index]\n",
        "                true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "                img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "                img_array = keras.preprocessing.image.img_to_array(img)\n",
        "                img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "                img_array = keras.applications.efficientnet_v2.preprocess_input(img_array)\n",
        "\n",
        "\n",
        "                prediction = model.predict(img_array)\n",
        "                predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "                predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"\\nSkipping random prediction as test_paths, test_labels, or label_encoder are not available.\")\n",
        "\n",
        "\n",
        "\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.subplot(1, 2, 1)\n",
        "\n",
        "            combined_accuracy = history_initial.history['accuracy'] + history_finetune.history['accuracy']\n",
        "            combined_val_accuracy = history_initial.history['val_accuracy'] + history_finetune.history['val_accuracy']\n",
        "            plt.plot(combined_accuracy)\n",
        "            plt.plot(combined_val_accuracy)\n",
        "            plt.title('Combined Model Accuracy (Initial + Fine-tuning)')\n",
        "            plt.ylabel('Accuracy')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            combined_loss = history_initial.history['loss'] + history_finetune.history['loss']\n",
        "            combined_val_loss = history_initial.history['val_loss'] + history_finetune.history['val_loss']\n",
        "            plt.plot(combined_loss)\n",
        "            plt.plot(combined_val_loss)\n",
        "            plt.title('Combined Model Loss (Initial + Fine-tuning)')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4OkQ-Azv8Ho"
      },
      "source": [
        "# EficientNetB7 + DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSpAC4i8vJxe"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "print(f\"Loading EfficientNetB7 model with input shape ({IMG_SIZE}, {IMG_SIZE}, 3)...\")\n",
        "base_model = EfficientNetB7(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "print(\"Freezing base EfficientNetB7 layers for initial training...\")\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "\n",
        "if 'train_labels_categorical' not in globals():\n",
        "    print(\"Error: 'train_labels_categorical' is not defined. Cannot determine number of classes.\")\n",
        "\n",
        "    num_classes = 4\n",
        "    print(f\"Assuming {num_classes} classes.\")\n",
        "else:\n",
        "    num_classes = train_labels_categorical.shape[1]\n",
        "    print(f\"Detected {num_classes} classes from train_labels_categorical.\")\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled for initial training (base layers frozen).\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=7, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "train_data_to_use = train_ds if 'augmented_train_data' in globals() and augmented_train_data.samples > 0 else train_data\n",
        "\n",
        "if 'train_data' not in globals() and ('augmented_train_data' not in globals() or augmented_train_data.samples == 0):\n",
        "     print(\"Error: Training data generator ('train_data' or 'augmented_train_data') not found or is empty.\")\n",
        "else:\n",
        "\n",
        "    epochs_initial = 20\n",
        "    print(f\"\\nStarting initial training for {epochs_initial} epochs (base layers frozen)...\")\n",
        "\n",
        "\n",
        "    if 'val_data' not in globals():\n",
        "         print(\"Error: Validation data generator ('val_data') not found.\")\n",
        "    else:\n",
        "        history_initial = model.fit(\n",
        "            train_data_to_use,\n",
        "            epochs=epochs_initial,\n",
        "            validation_data=val_ds,\n",
        "            #callbacks=[early_stopping, lr_reduction]\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"\\nUnfreezing layers for fine-tuning...\")\n",
        "\n",
        "\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = True\n",
        "\n",
        "\n",
        "        num_layers_to_unfreeze = 50\n",
        "\n",
        "\n",
        "        for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
        "            layer.trainable = False\n",
        "        print(f\"Unfrozen {num_layers_to_unfreeze} layers in the base model for fine-tuning.\")\n",
        "\n",
        "\n",
        "        optimizer_finetune = Adam(learning_rate=0.001)\n",
        "        model.compile(optimizer=optimizer_finetune, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        print(\"Model recompiled for fine-tuning with a very low learning rate.\")\n",
        "        model.summary()\n",
        "\n",
        "\n",
        "        epochs_finetune = 50\n",
        "        print(f\"\\nStarting fine-tuning for {epochs_finetune} epochs...\")\n",
        "\n",
        "\n",
        "        history_finetune = model.fit(\n",
        "            train_data_to_use,\n",
        "            epochs=epochs_finetune,\n",
        "            validation_data=val_ds,\n",
        "            #callbacks=[early_stopping, lr_reduction]\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"\\nEvaluating the fine-tuned EfficientNetB7 model on the test set...\")\n",
        "\n",
        "        if 'test_data' not in globals():\n",
        "            print(\"Error: Test data generator ('test_data') not found.\")\n",
        "        else:\n",
        "            loss_finetune, accuracy_finetune = model.evaluate(test_data)\n",
        "            print(f\"Fine-tuned Test Loss: {loss_finetune}\")\n",
        "            print(f\"Fine-tuned Test Accuracy: {accuracy_finetune}\")\n",
        "\n",
        "\n",
        "            print(\"\\nClassification Report for Fine-tuned EfficientNetB7:\")\n",
        "\n",
        "\n",
        "            if 'test_labels_encoded' in globals() and 'label_encoder' in globals():\n",
        "\n",
        "                y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "                y_pred_finetune = model.predict(test_data)\n",
        "                y_pred_classes_finetune = np.argmax(y_pred_finetune, axis=1)\n",
        "\n",
        "                report_finetune = classification_report(y_true, y_pred_classes_finetune, target_names=label_encoder.classes_)\n",
        "                print(report_finetune)\n",
        "            else:\n",
        "                 print(\"Error: 'test_labels_encoded' or 'label_encoder' not found. Cannot generate classification report.\")\n",
        "\n",
        "\n",
        "            model.save('efficientnetb7_finetuned_model.h5')\n",
        "            print(\"Fine-tuned EfficientNetB7 model saved successfully!\")\n",
        "\n",
        "\n",
        "            if 'test_paths' in globals() and 'test_labels' in globals() and 'label_encoder' in globals():\n",
        "                random_index = np.random.randint(0, len(test_paths))\n",
        "                image_path = test_paths[random_index]\n",
        "                true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "                img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "                img_array = keras.preprocessing.image.img_to_array(img)\n",
        "                img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "                try:\n",
        "\n",
        "                    from keras_applications.efficientnet import preprocess_input as efficientnet_preprocess_input\n",
        "                    img_array = efficientnet_preprocess_input(img_array)\n",
        "                except ImportError:\n",
        "                    print(\"Warning: keras_applications or tensorflow_addons not found. Using generic preprocessing.\")\n",
        "\n",
        "                    img_array /= 255.0\n",
        "\n",
        "\n",
        "\n",
        "                prediction = model.predict(img_array)\n",
        "                predicted_class_index = np.argmax(prediction)\n",
        "                predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"\\nSkipping random prediction as test_paths, test_labels, or label_encoder are not available.\")\n",
        "\n",
        "\n",
        "\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.subplot(1, 2, 1)\n",
        "\n",
        "            combined_accuracy = history_initial.history['accuracy'] + history_finetune.history['accuracy']\n",
        "            combined_val_accuracy = history_initial.history['val_accuracy'] + history_finetune.history['val_accuracy']\n",
        "            plt.plot(combined_accuracy)\n",
        "            plt.plot(combined_val_accuracy)\n",
        "            plt.title('Combined Model Accuracy (Initial + Fine-tuning)')\n",
        "            plt.ylabel('Accuracy')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            combined_loss = history_initial.history['loss'] + history_finetune.history['loss']\n",
        "            combined_val_loss = history_initial.history['val_loss'] + history_finetune.history['val_loss']\n",
        "            plt.plot(combined_loss)\n",
        "            plt.plot(combined_val_loss)\n",
        "            plt.title('Combined Model Loss (Initial + Fine-tuning)')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhcjlDzD0CH0"
      },
      "source": [
        "#MobileNetV2 + DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU2N9lVjvLZU"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenetv2_preprocess_input\n",
        "\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "print(\"Freezing base MobileNetV2 layers...\")\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "if 'train_labels_categorical' not in globals():\n",
        "    print(\"Error: 'train_labels_categorical' is not defined. Cannot determine number of classes.\")\n",
        "    num_classes = 4\n",
        "    print(f\"Assuming {num_classes} classes.\")\n",
        "else:\n",
        "    num_classes = train_labels_categorical.shape[1]\n",
        "    print(f\"Detected {num_classes} classes from train_labels_categorical.\")\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled for initial training (base layers frozen).\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "train_data_to_use = train_ds if 'augmented_train_data' in globals() and augmented_train_data.samples > 0 else train_data\n",
        "\n",
        "if 'train_data' not in globals() and ('augmented_train_data' not in globals() or augmented_train_data.samples == 0):\n",
        "     print(\"Error: Training data generator ('train_data' or 'augmented_train_data') not found or is empty.\")\n",
        "else:\n",
        "\n",
        "    epochs_initial = 20\n",
        "    print(f\"\\nStarting initial training for {epochs_initial} epochs (base layers frozen)...\")\n",
        "\n",
        "\n",
        "    if 'val_data' not in globals():\n",
        "         print(\"Error: Validation data generator ('val_data') not found.\")\n",
        "    else:\n",
        "        history_initial = model.fit(\n",
        "            train_data_to_use,\n",
        "            epochs=epochs_initial,\n",
        "            validation_data=val_ds,\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"\\nUnfreezing layers for fine-tuning...\")\n",
        "\n",
        "\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = True\n",
        "\n",
        "\n",
        "        num_layers_to_unfreeze = 30\n",
        "\n",
        "\n",
        "        for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
        "            layer.trainable = False\n",
        "        print(f\"Unfrozen {num_layers_to_unfreeze} layers in the base model for fine-tuning.\")\n",
        "\n",
        "\n",
        "        optimizer_finetune = Adam(learning_rate=0.0001)\n",
        "        model.compile(optimizer=optimizer_finetune, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        print(\"Model recompiled for fine-tuning with a lower learning rate.\")\n",
        "        model.summary()\n",
        "\n",
        "\n",
        "        epochs_finetune = 50\n",
        "        print(f\"\\nStarting fine-tuning for {epochs_finetune} epochs...\")\n",
        "\n",
        "        early_stopping_ft = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "        lr_reduction_ft = ReduceLROnPlateau(monitor='val_loss', patience=7, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "        history_finetune = model.fit(\n",
        "            train_data_to_use,\n",
        "            epochs=epochs_finetune,\n",
        "            validation_data=val_ds,\n",
        "            #callbacks=[early_stopping_ft, lr_reduction_ft]\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"\\nEvaluating the fine-tuned MobileNetV2 model on the test set...\")\n",
        "\n",
        "        if 'test_data' not in globals():\n",
        "            print(\"Error: Test data generator ('test_data') not found.\")\n",
        "        else:\n",
        "            loss_finetune, accuracy_finetune = model.evaluate(test_data)\n",
        "            print(f\"Fine-tuned Test Loss: {loss_finetune}\")\n",
        "            print(f\"Fine-tuned Test Accuracy: {accuracy_finetune}\")\n",
        "\n",
        "            print(\"\\nClassification Report for Fine-tuned MobileNetV2:\")\n",
        "\n",
        "\n",
        "            if 'test_labels_encoded' in globals() and 'label_encoder' in globals():\n",
        "\n",
        "                y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "                y_pred_finetune = model.predict(test_data)\n",
        "                y_pred_classes_finetune = np.argmax(y_pred_finetune, axis=1)\n",
        "\n",
        "                report_finetune = classification_report(y_true, y_pred_classes_finetune, target_names=label_encoder.classes_)\n",
        "                print(report_finetune)\n",
        "            else:\n",
        "                 print(\"Error: 'test_labels_encoded' or 'label_encoder' not found. Cannot generate classification report.\")\n",
        "\n",
        "\n",
        "            model.save('mobilenetv2_finetuned_model.h5')\n",
        "            print(\"Fine-tuned MobileNetV2 model saved successfully!\")\n",
        "\n",
        "\n",
        "            if 'test_paths' in globals() and 'test_labels' in globals() and 'label_encoder' in globals():\n",
        "                random_index = np.random.randint(0, len(test_paths))\n",
        "                image_path = test_paths[random_index]\n",
        "                true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "                img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "                img_array = keras.preprocessing.image.img_to_array(img)\n",
        "                img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "                img_array = mobilenetv2_preprocess_input(img_array)\n",
        "\n",
        "\n",
        "\n",
        "                prediction = model.predict(img_array)\n",
        "                predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "                predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"\\nSkipping random prediction as test_paths, test_labels, or label_encoder are not available.\")\n",
        "\n",
        "\n",
        "\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.subplot(1, 2, 1)\n",
        "\n",
        "            combined_accuracy = history_initial.history['accuracy'] + history_finetune.history['accuracy']\n",
        "            combined_val_accuracy = history_initial.history['val_accuracy'] + history_finetune.history['val_accuracy']\n",
        "            plt.plot(combined_accuracy)\n",
        "            plt.plot(combined_val_accuracy)\n",
        "            plt.title('Combined Model Accuracy (Initial + Fine-tuning)')\n",
        "            plt.ylabel('Accuracy')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            combined_loss = history_initial.history['loss'] + history_finetune.history['loss']\n",
        "            combined_val_loss = history_initial.history['val_loss'] + history_finetune.history['val_loss']\n",
        "            plt.plot(combined_loss)\n",
        "            plt.plot(combined_val_loss)\n",
        "            plt.title('Combined Model Loss (Initial + Fine-tuning)')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K5Y9ehFmMgT"
      },
      "source": [
        "# VGG19 + DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3eNb1mLzJgN"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "print(f\"Loading VGG19 model with input shape ({IMG_SIZE}, {IMG_SIZE}, 3)...\")\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "print(\"Freezing base VGG19 layers for initial training...\")\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "if 'train_labels_categorical' not in globals():\n",
        "    print(\"Error: 'train_labels_categorical' is not defined. Cannot determine number of classes.\")\n",
        "    num_classes = 4\n",
        "    print(f\"Assuming {num_classes} classes.\")\n",
        "else:\n",
        "    num_classes = train_labels_categorical.shape[1]\n",
        "    print(f\"Detected {num_classes} classes from train_labels_categorical.\")\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled for initial training (base layers frozen).\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=7, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "train_data_to_use = train_ds if 'augmented_train_data' in globals() and augmented_train_data.samples > 0 else train_data\n",
        "\n",
        "if 'train_data' not in globals() and ('augmented_train_data' not in globals() or augmented_train_data.samples == 0):\n",
        "     print(\"Error: Training data generator ('train_data' or 'augmented_train_data') not found or is empty.\")\n",
        "else:\n",
        "\n",
        "    epochs_initial = 20\n",
        "    print(f\"\\nStarting initial training for {epochs_initial} epochs (base layers frozen)...\")\n",
        "\n",
        "\n",
        "    if 'val_data' not in globals():\n",
        "         print(\"Error: Validation data generator ('val_data') not found.\")\n",
        "    else:\n",
        "        history_initial = model.fit(\n",
        "            train_data_to_use,\n",
        "            epochs=epochs_initial,\n",
        "            validation_data=val_ds,\n",
        "            #callbacks=[early_stopping, lr_reduction]\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"\\nUnfreezing layers for fine-tuning...\")\n",
        "\n",
        "\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = True\n",
        "\n",
        "\n",
        "        num_layers_to_unfreeze = 30\n",
        "\n",
        "\n",
        "        for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
        "            layer.trainable = False\n",
        "        print(f\"Unfrozen {num_layers_to_unfreeze} layers in the base model for fine-tuning.\")\n",
        "\n",
        "\n",
        "        optimizer_finetune = Adam(learning_rate=0.00001)\n",
        "        model.compile(optimizer=optimizer_finetune, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        print(\"Model recompiled for fine-tuning with a very low learning rate.\")\n",
        "        model.summary()\n",
        "\n",
        "\n",
        "        epochs_finetune = 50\n",
        "        print(f\"\\nStarting fine-tuning for {epochs_finetune} epochs...\")\n",
        "\n",
        "\n",
        "        early_stopping_ft = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "        lr_reduction_ft = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "        history_finetune = model.fit(\n",
        "            train_data_to_use,\n",
        "            epochs=epochs_finetune,\n",
        "            validation_data=val_ds,\n",
        "            #callbacks=[early_stopping_ft, lr_reduction_ft] # Use callbacks\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"\\nEvaluating the fine-tuned VGG19 model on the test set...\")\n",
        "\n",
        "        if 'test_data' not in globals():\n",
        "            print(\"Error: Test data generator ('test_data') not found.\")\n",
        "        else:\n",
        "            loss_finetune, accuracy_finetune = model.evaluate(test_data)\n",
        "            print(f\"Fine-tuned Test Loss: {loss_finetune}\")\n",
        "            print(f\"Fine-tuned Test Accuracy: {accuracy_finetune}\")\n",
        "\n",
        "\n",
        "            print(\"\\nClassification Report for Fine-tuned VGG19:\")\n",
        "\n",
        "\n",
        "            if 'test_labels_encoded' in globals() and 'label_encoder' in globals():\n",
        "\n",
        "                y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "                y_pred_finetune = model.predict(test_data)\n",
        "                y_pred_classes_finetune = np.argmax(y_pred_finetune, axis=1)\n",
        "\n",
        "                report_finetune = classification_report(y_true, y_pred_classes_finetune, target_names=label_encoder.classes_)\n",
        "                print(report_finetune)\n",
        "            else:\n",
        "                 print(\"Error: 'test_labels_encoded' or 'label_encoder' not found. Cannot generate classification report.\")\n",
        "\n",
        "\n",
        "            model.save('vgg19_finetuned_model.h5')\n",
        "            print(\"Fine-tuned VGG19 model saved successfully!\")\n",
        "\n",
        "\n",
        "            if 'test_paths' in globals() and 'test_labels' in globals() and 'label_encoder' in globals():\n",
        "                random_index = np.random.randint(0, len(test_paths))\n",
        "                image_path = test_paths[random_index]\n",
        "                true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "                img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "                img_array = keras.preprocessing.image.img_to_array(img)\n",
        "                img_array = np.expand_dims(img_array, axis=0)\n",
        "                img_array = preprocess_input(img_array)\n",
        "\n",
        "\n",
        "\n",
        "                prediction = model.predict(img_array)\n",
        "                predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "                predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"\\nSkipping random prediction as test_paths, test_labels, or label_encoder are not available.\")\n",
        "\n",
        "\n",
        "\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.subplot(1, 2, 1)\n",
        "\n",
        "            combined_accuracy = history_initial.history['accuracy'] + history_finetune.history['accuracy']\n",
        "            combined_val_accuracy = history_initial.history['val_accuracy'] + history_finetune.history['val_accuracy']\n",
        "            plt.plot(combined_accuracy)\n",
        "            plt.plot(combined_val_accuracy)\n",
        "            plt.title('Combined Model Accuracy (Initial + Fine-tuning)')\n",
        "            plt.ylabel('Accuracy')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            combined_loss = history_initial.history['loss'] + history_finetune.history['loss']\n",
        "            combined_val_loss = history_initial.history['val_loss'] + history_finetune.history['val_loss']\n",
        "            plt.plot(combined_loss)\n",
        "            plt.plot(combined_val_loss)\n",
        "            plt.title('Combined Model Loss (Initial + Fine-tuning)')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7RRSmGNmBSW"
      },
      "source": [
        "# VGG16 + DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsCFd8lD-zMn"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "print(f\"Loading VGG16 model with input shape ({IMG_SIZE}, {IMG_SIZE}, 3)...\")\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "\n",
        "print(\"Freezing base VGG16 layers for initial training...\")\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "if 'train_labels_categorical' not in globals():\n",
        "    print(\"Error: 'train_labels_categorical' is not defined. Cannot determine number of classes.\")\n",
        "\n",
        "    num_classes = 4\n",
        "    print(f\"Assuming {num_classes} classes.\")\n",
        "else:\n",
        "    num_classes = train_labels_categorical.shape[1]\n",
        "    print(f\"Detected {num_classes} classes from train_labels_categorical.\")\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled for initial training (base layers frozen).\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=7, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "train_data_to_use = train_ds if 'augmented_train_data' in globals() and augmented_train_data.samples > 0 else train_data\n",
        "\n",
        "if 'train_data' not in globals() and ('augmented_train_data' not in globals() or augmented_train_data.samples == 0):\n",
        "     print(\"Error: Training data generator ('train_data' or 'augmented_train_data') not found or is empty.\")\n",
        "else:\n",
        "\n",
        "    epochs_initial = 20\n",
        "    print(f\"\\nStarting initial training for {epochs_initial} epochs (base layers frozen)...\")\n",
        "\n",
        "\n",
        "    if 'val_data' not in globals():\n",
        "         print(\"Error: Validation data generator ('val_data') not found.\")\n",
        "    else:\n",
        "        history_initial = model.fit(\n",
        "            train_data_to_use,\n",
        "            epochs=epochs_initial,\n",
        "            validation_data=val_ds,\n",
        "            #callbacks=[early_stopping, lr_reduction]\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"\\nUnfreezing layers for fine-tuning...\")\n",
        "\n",
        "\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = True\n",
        "\n",
        "\n",
        "        num_layers_to_unfreeze = 30\n",
        "\n",
        "\n",
        "        for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
        "            layer.trainable = False\n",
        "        print(f\"Unfrozen {num_layers_to_unfreeze} layers in the base model for fine-tuning.\")\n",
        "\n",
        "\n",
        "        optimizer_finetune = Adam(learning_rate=0.00001)\n",
        "        model.compile(optimizer=optimizer_finetune, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        print(\"Model recompiled for fine-tuning with a very low learning rate.\")\n",
        "        model.summary()\n",
        "\n",
        "\n",
        "        epochs_finetune = 50\n",
        "        print(f\"\\nStarting fine-tuning for {epochs_finetune} epochs...\")\n",
        "\n",
        "\n",
        "        early_stopping_ft = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "        lr_reduction_ft = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "        history_finetune = model.fit(\n",
        "            train_data_to_use,\n",
        "            epochs=epochs_finetune,\n",
        "            validation_data=val_data,\n",
        "            #callbacks=[early_stopping_ft, lr_reduction_ft]\n",
        "        )\n",
        "\n",
        "\n",
        "        print(\"\\nEvaluating the fine-tuned VGG16 model on the test set...\")\n",
        "\n",
        "        if 'test_data' not in globals():\n",
        "            print(\"Error: Test data generator ('test_data') not found.\")\n",
        "        else:\n",
        "            loss_finetune, accuracy_finetune = model.evaluate(test_data)\n",
        "            print(f\"Fine-tuned Test Loss: {loss_finetune}\")\n",
        "            print(f\"Fine-tuned Test Accuracy: {accuracy_finetune}\")\n",
        "\n",
        "\n",
        "            print(\"\\nClassification Report for Fine-tuned VGG16:\")\n",
        "\n",
        "\n",
        "            if 'test_labels_encoded' in globals() and 'label_encoder' in globals():\n",
        "\n",
        "                y_true = test_labels_encoded\n",
        "\n",
        "\n",
        "                y_pred_finetune = model.predict(test_data)\n",
        "                y_pred_classes_finetune = np.argmax(y_pred_finetune, axis=1)\n",
        "\n",
        "                report_finetune = classification_report(y_true, y_pred_classes_finetune, target_names=label_encoder.classes_)\n",
        "                print(report_finetune)\n",
        "            else:\n",
        "                 print(\"Error: 'test_labels_encoded' or 'label_encoder' not found. Cannot generate classification report.\")\n",
        "\n",
        "\n",
        "            model.save('vgg16_finetuned_model.h5')\n",
        "            print(\"Fine-tuned VGG16 model saved successfully!\")\n",
        "\n",
        "\n",
        "            if 'test_paths' in globals() and 'test_labels' in globals() and 'label_encoder' in globals():\n",
        "                random_index = np.random.randint(0, len(test_paths))\n",
        "                image_path = test_paths[random_index]\n",
        "                true_label = test_labels[random_index]\n",
        "\n",
        "\n",
        "                img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "                img_array = keras.preprocessing.image.img_to_array(img)\n",
        "                img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "                img_array = preprocess_input(img_array)\n",
        "\n",
        "\n",
        "\n",
        "                prediction = model.predict(img_array)\n",
        "                predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "                predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"\\nSkipping random prediction as test_paths, test_labels, or label_encoder are not available.\")\n",
        "\n",
        "\n",
        "\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.subplot(1, 2, 1)\n",
        "\n",
        "            combined_accuracy = history_initial.history['accuracy'] + history_finetune.history['accuracy']\n",
        "            combined_val_accuracy = history_initial.history['val_accuracy'] + history_finetune.history['val_accuracy']\n",
        "            plt.plot(combined_accuracy)\n",
        "            plt.plot(combined_val_accuracy)\n",
        "            plt.title('Combined Model Accuracy (Initial + Fine-tuning)')\n",
        "            plt.ylabel('Accuracy')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            combined_loss = history_initial.history['loss'] + history_finetune.history['loss']\n",
        "            combined_val_loss = history_initial.history['val_loss'] + history_finetune.history['val_loss']\n",
        "            plt.plot(combined_loss)\n",
        "            plt.plot(combined_val_loss)\n",
        "            plt.title('Combined Model Loss (Initial + Fine-tuning)')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_GYLGjJoLDb"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vision Transformer"
      ],
      "metadata": {
        "id": "zBJcjz29Y6kt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8Nt20zBp9p4"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Load model and freeze all but classifier\n",
        "model = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=len(class_names))\n",
        "model.to(device)\n",
        "\n",
        "# Freeze all ViT backbone layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the classification head\n",
        "for param in model.head.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Optimizer only for head\n",
        "optimizer = optim.Adam(model.head.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs_head = 5  # Train head for a few epochs\n",
        "\n",
        "print(\"\\n Training classification head only...\\n\")\n",
        "for epoch in range(epochs_head):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs_head} - Head Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Head Epoch {epoch+1}: Loss={running_loss/len(train_loader):.4f} | Acc={100*correct/total:.2f}%\")\n",
        "\n",
        "# STEP 2: Unfreeze all layers for fine-tuning\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# New optimizer for full model with smaller LR\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
        "epochs_finetune = 20\n",
        "\n",
        "print(\"\\n Fine-tuning the entire model...\\n\")\n",
        "best_val_acc = 0.0\n",
        "for epoch in range(epochs_finetune):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs_finetune} - Fine-tuning\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Finetune Epoch {epoch+1}: Train Acc={train_accuracy:.2f}% | Val Acc={val_accuracy:.2f}%\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_accuracy > best_val_acc:\n",
        "        best_val_acc = val_accuracy\n",
        "        best_model_state = model.state_dict()\n",
        "        torch.save(model.state_dict(), \"best_finetuned_vit.pth\")\n",
        "        print(\" Best model saved.\")\n",
        "\n",
        "print(f\"\\n Best Validation Accuracy: {best_val_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWA14QvYsp6P"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "train_correct = 0\n",
        "train_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "train_accuracy = 100 * train_correct / train_total\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "test_accuracy = 100 * np.sum(np.array(y_true) == np.array(y_pred)) / len(y_true)\n",
        "print(f\"Testing Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **X-RVV with Data Augmentation**"
      ],
      "metadata": {
        "id": "CgacA0TQUoBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.applications import ResNet50, VGG19\n",
        "from keras.layers import Input, Dense, Dropout, concatenate, GlobalAveragePooling2D, Resizing, Rescaling\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from transformers import TFViTModel\n",
        "import segmentation_models as sm\n",
        "\n",
        "\n",
        "vit_model = TFViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "\n",
        "input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='input_layer')\n",
        "\n",
        "\n",
        "resnet = ResNet50(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "resnet_out = GlobalAveragePooling2D()(resnet.output)\n",
        "\n",
        "\n",
        "vgg = VGG19(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "vgg_out = GlobalAveragePooling2D()(vgg.output)\n",
        "\n",
        "\n",
        "vit_input = Resizing(224, 224)(input_tensor)\n",
        "vit_input = Rescaling(1./255)(vit_input)\n",
        "\n",
        "class TransposeLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.transpose(inputs, perm=[0, 3, 1, 2])\n",
        "\n",
        "vit_input_transposed = TransposeLayer()(vit_input)\n",
        "\n",
        "class ViTBranch(tf.keras.layers.Layer):\n",
        "    def call(self, inputs, training=False):\n",
        "        outputs = vit_model({'pixel_values': inputs})\n",
        "        return outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "vit_out = ViTBranch()(vit_input_transposed)\n",
        "\n",
        "\n",
        "merged = concatenate([resnet_out, vgg_out, vit_out])\n",
        "x = Dense(1024, activation='relu')(merged)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "classification_output = Dense(NUM_CLASSES, activation='softmax', name='classification_output')(x)\n",
        "\n",
        "segmentation_output = sm.Unet(\n",
        "    backbone_name='resnet34',\n",
        "    encoder_weights='imagenet',\n",
        "    classes=1,\n",
        "    activation='sigmoid'\n",
        ")(input_tensor)\n",
        "segmentation_output._name = 'segmentation_output'\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=[classification_output, segmentation_output], name=\"functional_37\")\n",
        "\n",
        "\n",
        "classification_model = Model(inputs=model.input, outputs=model.get_layer('classification_output').output, name=\"functional_37\")\n",
        "\n",
        "\n",
        "classification_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "classification_model.summary()\n"
      ],
      "metadata": {
        "id": "uHshF04mNePn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = classification_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=50,\n",
        "    callbacks=[\n",
        "        keras.callbacks.ModelCheckpoint('best_hybrid_model2.keras', save_best_only=True)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "OLibhDvznCR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p9LM1qnvtowS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model.save('best_hybrid_classification_model3.keras')"
      ],
      "metadata": {
        "id": "mawXeO6Qs4Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Hybrid model on Test Data"
      ],
      "metadata": {
        "id": "rnQi3bXpBl8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = classification_model.evaluate(test_ds)\n",
        "print(f\" Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "Y-z8CJV3WWyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    preds = classification_model.predict(images)\n",
        "    y_true.extend(tf.argmax(labels, axis=1).numpy())\n",
        "    y_pred.extend(tf.argmax(preds, axis=1).numpy())\n",
        "\n",
        "y_true = tf.convert_to_tensor(y_true)\n",
        "y_pred = tf.convert_to_tensor(y_pred)"
      ],
      "metadata": {
        "id": "1bdpvQEKObvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class_names = ['glioma', 'meningioma', 'no_tumor', 'pituitary']\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
      ],
      "metadata": {
        "id": "8HjaI1wBK8VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(\"Confusion Matrix - Test Set\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nhsy8hCdth1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "y_true_auc = []\n",
        "y_prob = []\n",
        "\n",
        "\n",
        "for images, labels in test_ds:\n",
        "\n",
        "    probs = classification_model.predict(images, verbose=0)\n",
        "\n",
        "    y_true_auc.extend(tf.argmax(labels, axis=1).numpy())\n",
        "\n",
        "    y_prob.extend(probs)\n",
        "\n",
        "y_true_auc = np.array(y_true_auc)\n",
        "y_prob = np.array(y_prob)\n",
        "\n",
        "\n",
        "auc_score_ovr = roc_auc_score(y_true_auc, y_prob, multi_class='ovr')\n",
        "\n",
        "\n",
        "auc_score_macro = roc_auc_score(y_true_auc, y_prob, multi_class='ovr', average='macro')\n",
        "\n",
        "auc_score_weighted = roc_auc_score(y_true_auc, y_prob, multi_class='ovr', average='weighted')\n",
        "\n",
        "\n",
        "print(f\"\\nAUC Score (One-vs-Rest): {auc_score_ovr:.4f}\")\n",
        "print(f\"AUC Score (Macro Average): {auc_score_macro:.4f}\")\n",
        "print(f\"AUC Score (Weighted Average): {auc_score_weighted:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nAUC per Class:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "\n",
        "    y_true_class = (y_true_auc == i).astype(int)\n",
        "\n",
        "    y_prob_class = y_prob[:, i]\n",
        "\n",
        "    auc_class = roc_auc_score(y_true_class, y_prob_class)\n",
        "    print(f\"AUC for class '{class_name}': {auc_class:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "n_classes = len(class_names)\n",
        "\n",
        "for i in range(n_classes):\n",
        "\n",
        "    y_true_bin = (y_true_auc == i).astype(int)\n",
        "\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_bin, y_prob[:, i])\n",
        "\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve - Per Class (OvR)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "for i in range(n_classes):\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for Class: {class_names[i]}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "2-m0JefSLJsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GradCAM Implementation"
      ],
      "metadata": {
        "id": "YJyjRnxMB7W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from transformers import TFViTModel\n",
        "import keras\n",
        "\n",
        "\n",
        "@keras.saving.register_keras_serializable()\n",
        "class ViTBranch(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vit = TFViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        return self.vit({'pixel_values': inputs}, training=training).last_hidden_state[:, 0, :]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], 768)\n",
        "\n",
        "\n",
        "@keras.saving.register_keras_serializable()\n",
        "class TransposeLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.transpose(inputs, perm=[0, 3, 1, 2])\n",
        "\n",
        "\n",
        "model = tf.keras.models.load_model('best_hybrid_classification_model3.keras',\n",
        "                                   custom_objects={'TransposeLayer': TransposeLayer, 'ViTBranch': ViTBranch})\n",
        "\n",
        "\n",
        "def generate_gradcam(model, img, class_index, target_layer='conv5_block3_out'):\n",
        "    \"\"\"Generates Grad-CAM++ visualization for classification without segmentation.\"\"\"\n",
        "    img_resized = cv2.resize(img, (224, 224))\n",
        "    x = tf.keras.applications.resnet50.preprocess_input(np.expand_dims(img_resized.copy(), axis=0))\n",
        "\n",
        "\n",
        "    classification_output_layer = model.get_layer('classification_output')\n",
        "    grad_model = tf.keras.models.Model([model.input],\n",
        "                                       [model.get_layer(target_layer).output, classification_output_layer.output])\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(x)\n",
        "        loss = predictions[:, class_index]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap + 1e-8)\n",
        "    heatmap = tf.image.resize(heatmap[..., tf.newaxis], (224, 224), method='bilinear')\n",
        "    heatmap = tf.squeeze(heatmap).numpy()\n",
        "\n",
        "\n",
        "    heatmap = np.power(heatmap, 2.5)\n",
        "    heatmap[heatmap < 0.4] = 0\n",
        "\n",
        "\n",
        "    heatmap_uint8 = np.uint8(255 * heatmap)\n",
        "    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
        "\n",
        "\n",
        "    gray_img = cv2.cvtColor(img_resized.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
        "    gray_img = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2BGR)\n",
        "    overlay = cv2.addWeighted(gray_img, 0.7, heatmap_color, 0.6, 0)\n",
        "\n",
        "    return overlay, img_resized\n",
        "\n",
        "\n",
        "def plot_top1_correct_gradcam(model, test_ds, class_names):\n",
        "    \"\"\"Plots Grad-CAM++ for top-1 correct prediction (classification only).\"\"\"\n",
        "    correct_predictions = []\n",
        "    count = 0\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "        for i in range(len(images)):\n",
        "            img = images[i].numpy()\n",
        "            label = tf.argmax(labels[i]).numpy()\n",
        "\n",
        "            preds = model.predict(np.expand_dims(img, axis=0))\n",
        "            pred_class = np.argmax(preds[0])\n",
        "\n",
        "            if pred_class == label:\n",
        "                correct_predictions.append((img, label, pred_class))\n",
        "                count += 1\n",
        "                if count == 1:\n",
        "                    break\n",
        "        if count == 1:\n",
        "            break\n",
        "\n",
        "    for img, label, pred_class in correct_predictions:\n",
        "        overlay, base_img = generate_gradcam(model, img, pred_class)\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(cv2.cvtColor(base_img, cv2.COLOR_RGB2GRAY), cmap='gray')\n",
        "        plt.title(f\"Original MRI\\nTrue: {class_names[label]}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"Grad-CAM++ Overlay\\nPredicted: {class_names[pred_class]}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plot_top1_correct_gradcam(model, test_ds, class_names)\n"
      ],
      "metadata": {
        "id": "TlcpUdhSycrI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}